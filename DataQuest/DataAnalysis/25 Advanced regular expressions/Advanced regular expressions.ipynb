{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this mission, we're going to build on those foundational principles, and learn:\n",
    "\n",
    "Several new regex syntax components to allow us to express more complex criteria.\n",
    "\n",
    "- How to combine regular expression patterns to extract and transform data.\n",
    "- How to replace and clean data using regular expressions.\n",
    "-\n",
    "We're going to continue working with the dataset from the previous mission from technology site Hacker News. Let's take a moment to refresh our memory of the different columns in this dataset:\n",
    "\n",
    "- id: The unique identifier from Hacker News for the story\n",
    "- title: The title of the story\n",
    "- url: The URL that the stories links to, if the story has a URL\n",
    "- num_points: The number of points the story acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- num_comments: The number of comments that were made on the story\n",
    "- author: The username of the person who submitted the story\n",
    "- created_at: The date and time at which the story was submitted\n",
    "\n",
    "We'll continue to analyze and count mentions of different programming languages in the dataset, and then we'll finish by extracting the different components of the URLs submitted to Hacker News.\n",
    "\n",
    "As we mentioned in the previous mission, you shouldn't expect to remember every single detail of regular expression syntax. The most important thing is to understand the core principles, what is possible, and where to look up the details. This will mean you can quickly jog your memory whenever you need regular expressions.\n",
    "\n",
    "We'll be building on the foundational concepts that we learned in the previous mission. If you need to refresh any points of the syntax while you complete exercises in this mission, we recommend using a regex syntax reference like RegExr so you can practice looking up syntax as you need it.\n",
    "\n",
    "Let's start by reading in the dataset using pandas and extracting the story titles from the title column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "hn = pd.read_csv(\"hacker_news.csv\")\n",
    "titles = hn['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the story titles, we have two different capitalizations for the Python language: Python and python. In the previous mission, we learned two techniques for handling cases like these. The first is to use a set to match either P or p:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"[Pp]ython\"\n",
    "python_counts = titles.str.contains(pattern).sum()\n",
    "print(python_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second option we learned is to use re.I — the ignorecase flag — to make our pattern case insensitive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"python\"\n",
    "python_counts = titles.str.contains(pattern, flags=re.I).sum()\n",
    "print(python_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ignorecase flag is particularly useful when we have many different capitalizations for a word or phrase. In our dataset, the SQL language has three different capitalizations: SQL, sql, and Sql.\n",
    "\n",
    "To use sets to capture all of these variations, we would need to use a set for each character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"[Ss][Qq][Ll]\"\n",
    "sql_counts = titles.str.contains(pattern).sum()\n",
    "print(sql_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, let's use the ignorecase flag to write a case-insensitive version of this regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_counts = titles.str.contains(r'sql', flags = re.I).sum()\n",
    "sql_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture groups\n",
    "\n",
    "Let's look at how we can use a capture group to create a frequency table of the different capitalizations of SQL in our dataset. We start by wrapping our regex pattern in parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(SQL)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use Series.str.extract() to extract the different capitalizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_capitalizations = titles.str.extract(pattern, flags=re.I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we use the Series.value_counts() method to create a frequency table of those capitalizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL    101\n",
      "Sql      4\n",
      "sql      3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sql_capitalizations_freq = sql_capitalizations.value_counts()\n",
    "print(sql_capitalizations_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extend this analysis by looking at titles that have letters immediately before the \"SQL,\" which is a convention often used to denote different variations or flavors of SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL    27\n",
      "NoSQL         16\n",
      "MySQL         12\n",
      "CloudSQL       1\n",
      "MemSQL         1\n",
      "SparkSQL       1\n",
      "mySql          1\n",
      "nosql          1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"(\\w+SQL)\"\n",
    "sql_flavors = titles.str.extract(pattern, flags=re.I)\n",
    "sql_flavors_freq = sql_flavors.value_counts()\n",
    "print(sql_flavors_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how there is some duplication due to varied capitalization in this frequency table:\n",
    "\n",
    "- NoSQL and nosql\n",
    "- MySQL and mysql\n",
    "\n",
    "In this exercise, we're going to extract the mentions of different SQL flavors into a new column and clean those duplicates by making them all lowercase. We'll then analyze the results to look at the average number of comments for each flavor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>num_points</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>10957172</td>\n",
       "      <td>PostgreSQL: Linux VS Windows  part 2</td>\n",
       "      <td>http://www.sqig.net/2016/01/postgresql-linux-v...</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>based2</td>\n",
       "      <td>1/23/2016 4:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>11544342</td>\n",
       "      <td>MemSQL (YC W11) Raises $36M Series C</td>\n",
       "      <td>http://blog.memsql.com/memsql-raises-series-c/</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "      <td>ericfrenkiel</td>\n",
       "      <td>4/21/2016 18:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>10413272</td>\n",
       "      <td>Pgmemcahe :A PostgreSQL memcache functions</td>\n",
       "      <td>https://github.com/ohmu/pgmemcache/</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>websec</td>\n",
       "      <td>10/19/2015 14:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>10546681</td>\n",
       "      <td>How to choose an in-memory NoSQL solution: Per...</td>\n",
       "      <td>http://articles.rvncerr.org/how-to-chose-an-in...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>rvncerr</td>\n",
       "      <td>11/11/2015 14:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>11583183</td>\n",
       "      <td>Postgraphql: A GraphQL schema created by refle...</td>\n",
       "      <td>https://github.com/calebmer/postgraphql</td>\n",
       "      <td>217</td>\n",
       "      <td>24</td>\n",
       "      <td>craigkerstiens</td>\n",
       "      <td>4/27/2016 18:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "142   10957172               PostgreSQL: Linux VS Windows  part 2   \n",
       "221   11544342               MemSQL (YC W11) Raises $36M Series C   \n",
       "882   10413272         Pgmemcahe :A PostgreSQL memcache functions   \n",
       "1160  10546681  How to choose an in-memory NoSQL solution: Per...   \n",
       "1197  11583183  Postgraphql: A GraphQL schema created by refle...   \n",
       "\n",
       "                                                    url  num_points  \\\n",
       "142   http://www.sqig.net/2016/01/postgresql-linux-v...          16   \n",
       "221      http://blog.memsql.com/memsql-raises-series-c/          74   \n",
       "882                 https://github.com/ohmu/pgmemcache/           2   \n",
       "1160  http://articles.rvncerr.org/how-to-chose-an-in...           9   \n",
       "1197            https://github.com/calebmer/postgraphql         217   \n",
       "\n",
       "      num_comments          author        created_at  \n",
       "142              3          based2    1/23/2016 4:21  \n",
       "221             14    ericfrenkiel   4/21/2016 18:32  \n",
       "882              1          websec  10/19/2015 14:55  \n",
       "1160             4         rvncerr  11/11/2015 14:04  \n",
       "1197            24  craigkerstiens   4/27/2016 18:29  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn_sql = hn[hn['title'].str.contains(r\"\\w+SQL\", flags=re.I)].copy()\n",
    "hn_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                Interactive Dynamic Video\n",
       "1        Florida DJs May Face Felony for April Fools' W...\n",
       "2             Technology ventures: From Idea to Enterprise\n",
       "3        Note by Note: The Making of Steinway L1037 (2007)\n",
       "4        Title II kills investment? Comcast and other I...\n",
       "                               ...                        \n",
       "20094    How Purism Avoids Intels Active Management Tec...\n",
       "20095            YC Application Translated and Broken Down\n",
       "20096    Microkernels are slow and Elvis didn't do no d...\n",
       "20097                        How Product Hunt really works\n",
       "20098    RoboBrowser: Your friendly neighborhood web sc...\n",
       "Name: title, Length: 20099, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = hn['title']\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142     PostgreSQL\n",
       "221         MemSQL\n",
       "882     PostgreSQL\n",
       "1160         NoSQL\n",
       "1197    PostgreSQL\n",
       "Name: flavor, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn_sql['flavor'] = titles.str.extract(r\"(\\w+SQL)\", flags = re.I)\n",
    "hn_sql['flavor'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142     postgresql\n",
       "221         memsql\n",
       "882     postgresql\n",
       "1160         nosql\n",
       "1197    postgresql\n",
       "Name: flavor, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn_sql['flavor'] = hn_sql['flavor'].str.lower()\n",
    "hn_sql['flavor'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flavor</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cloudsql</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memsql</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mysql</th>\n",
       "      <td>12.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nosql</th>\n",
       "      <td>14.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postgresql</th>\n",
       "      <td>25.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sparksql</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            num_comments\n",
       "flavor                  \n",
       "cloudsql        5.000000\n",
       "memsql         14.000000\n",
       "mysql          12.230769\n",
       "nosql          14.529412\n",
       "postgresql     25.962963\n",
       "sparksql        1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_pivot = hn_sql.pivot_table(index = 'flavor', values = 'num_comments')\n",
    "sql_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using capture groups to extract data\n",
    "\n",
    "So far we've used capture groups to extract all or most of the text in our regular expression pattern. Capture groups can also be useful to extract specific data from within our expression.\n",
    "\n",
    "Let's look at a sample of Hacker News titles that mention Python:\n",
    "\n",
    "```\n",
    "Developing a computational pipeline using the asyncio module in Python 3\n",
    "Python 3 on Google App Engine flexible environment now in beta\n",
    "Python 3.6 proposal, PEP 525: Asynchronous Generators\n",
    "How async/await works in Python 3.5.0\n",
    "Ubuntu Drops Python 2.7 from the Default Install in 16.04\n",
    "Show HN: First Release of Transcrypt Python3.5 to JavaScript Compiler\n",
    "```\n",
    "\n",
    "All of these examples have a number after the word \"Python,\" which indicates a version number. Sometimes a space precedes the number, sometimes it doesn't. We can use the following regular expression to match these cases:\n",
    "\n",
    "![img](img/python.png)\n",
    "\n",
    "We can use capture groups to extract the version of Python that is mentioned most often in our dataset by wrapping parentheses around the part of our regular expression which captures the version number.\n",
    "\n",
    "We'll use a capture group to capture the version number after the word \"Python,\" and then build a frequency table of the different versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3        10\n",
       "2         3\n",
       "3.5       3\n",
       "3.6       2\n",
       "1.5       1\n",
       "2.7       1\n",
       "3.5.0     1\n",
       "4         1\n",
       "8         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'[Pp]ython ([\\d\\.]+)'\n",
    "\n",
    "py_versions = titles.str.extract(pattern).value_counts()\n",
    "py_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('3',): 10,\n",
       " ('2',): 3,\n",
       " ('3.5',): 3,\n",
       " ('3.6',): 2,\n",
       " ('1.5',): 1,\n",
       " ('2.7',): 1,\n",
       " ('3.5.0',): 1,\n",
       " ('4',): 1,\n",
       " ('8',): 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_versions.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting mentions of the 'C' language\n",
    "\n",
    "So far, we've created regular expressions to clean and analyze the number of mentions of the Python, SQL, and Java languages. Next up: counting the mentions of the C language.\n",
    "\n",
    "We can start with a simple regular expression and then iterate as we find and exclude incorrect matches. Let's start with a simple regex that matches the letter \"c\" with word boundary anchors on either side:\n",
    "\n",
    "![img](img/C.png)\n",
    "\n",
    "We'll re-use the first_10_matches() function that we defined in the previous mission to see the results we get from this regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13                 Custom Deleters for C++ Smart Pointers\n",
       "220                        Lisp, C++: Sadness in my heart\n",
       "221                  MemSQL (YC W11) Raises $36M Series C\n",
       "353     VW C.E.O. Personally Apologized to President O...\n",
       "365                      The new C standards are worth it\n",
       "444           Moz raises $10m Series C from Foundry Group\n",
       "508     BDE 3.0 (Bloomberg's core C++ library): Open S...\n",
       "521          Fuchsia: Micro kernel written in C by Google\n",
       "549     How to Become a C.E.O.? The Quickest Path Is a...\n",
       "1282    A lightweight C++ signals and slots implementa...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def first_10_matches(pattern):\n",
    "    \"\"\"\n",
    "    Return the first 10 story titles that match\n",
    "    the provided regular expression\n",
    "    \"\"\"\n",
    "    all_matches = titles[titles.str.contains(pattern)]\n",
    "    first_10 = all_matches.head(10)\n",
    "    return first_10\n",
    "\n",
    "first_10_matches(r\"\\b[Cc]\\b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately, our results are reasonably relevant. However, we can quickly identify a few match types we want to prevent:\n",
    "\n",
    "- Mentions of C++, a distinct language from C.\n",
    "- Cases where the letter C is followed by a period, like in the substring C.E.O.\n",
    "\n",
    "Let's use a negative set to prevent matches for the + character and the . character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365                      The new C standards are worth it\n",
       "444           Moz raises $10m Series C from Foundry Group\n",
       "521          Fuchsia: Micro kernel written in C by Google\n",
       "1307            Show HN: Yupp, yet another C preprocessor\n",
       "1326                     The C standard formalized in Coq\n",
       "1365                          GNU C Library 2.23 released\n",
       "1429    Cysignals: signal handling (SIGINT, SIGSEGV, )...\n",
       "1620                        SDCC  Small Device C Compiler\n",
       "1949    Rewriting a Ruby C Extension in Rust: How a Na...\n",
       "2195    MyHTML  HTML Parser on Pure C with POSIX Threa...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"\\b[Cc]\\b[^.+]\"\n",
    "\n",
    "first_10_matches(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using lookarounds to control matches based on surrounding text\n",
    "\n",
    "It looks like we're getting close. In our first 10 matches we have one irrelevant result, which is about \"Series C,\" a term used to represent a particular type of startup fundraising.\n",
    "\n",
    "Additionally, we've run into the same issue as we did in the previous mission — by using a negative set, we may have eliminated any instances where the last character of the title is \"C\" (the second last line of output matches in spite of the fact that it ends with \"C,\" because it also has \"C\" earlier in the string).\n",
    "\n",
    "Neither of these can be avoided using negative sets, which are used to allow multiple matches for a single character. Instead we'll need a new tool: **lookarounds.**\n",
    "\n",
    "Lookarounds let us define a character or sequence of characters that either must or must not come before or after our regex match. There are four types of lookarounds:\n",
    "\n",
    "![img](img/look.png)\n",
    "\n",
    "These tips can help you remember the syntax for lookarounds:\n",
    "\n",
    "- Inside the parentheses, the first character of a lookaround is always `?`.\n",
    "- If the lookaround is a **lookbehind**, the next character will be `<`, which you can think of as an arrow head pointing behind the match.\n",
    "- The next character indicates whether the lookaround is positive (`=`) or negative (`!`).\n",
    "\n",
    "Let's create some test data that we'll use to illustrate how lookarounds work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = ['Red_Green_Blue',\n",
    "              'Yellow_Green_Red',\n",
    "              'Red_Green_Red',\n",
    "              'Yellow_Green_Blue',\n",
    "              'Green']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create a function that will loop over our test cases and tell us whether our pattern matches. We'll use the re module rather than pandas since it tells us the exact text that matches, which will help us understand how the lookaround is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_cases(pattern):\n",
    "    for tc in test_cases:\n",
    "        result = re.search(pattern, tc)\n",
    "        print(result or \"NO MATCH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each instance, we'll aim to match the substring Green depending on the characters that precede or follow it. Let's start by using a positive lookahead to include instances where the match is followed by the substring _Blue. We'll include the underscore character in the lookahead, otherwise we will get zero matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "NO MATCH\n",
      "<re.Match object; span=(7, 12), match='Green'>\n",
      "NO MATCH\n"
     ]
    }
   ],
   "source": [
    "run_test_cases(r\"Green(?=_Blue)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the matches themselves are purely the text Green and don't include the lookahead. Let's look at a negative lookahead to include instances where the match is not followed by the substring _Red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "NO MATCH\n",
      "<re.Match object; span=(7, 12), match='Green'>\n",
      "<re.Match object; span=(0, 5), match='Green'>\n"
     ]
    }
   ],
   "source": [
    "run_test_cases(r\"Green(?!_Red)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use a positive lookbehind to include instances where the match is preceded by the substring Red_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "NO MATCH\n"
     ]
    }
   ],
   "source": [
    "run_test_cases(r\"(?<=Red_)Green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, using a negative lookbehind to include instances where the match isn't preceded by the substring Yellow_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "<re.Match object; span=(0, 5), match='Green'>\n"
     ]
    }
   ],
   "source": [
    "run_test_cases(r\"(?<!Yellow_)Green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of a lookaround can include any other regular expression component. For instance, here is an example where we match only cases that are followed by exactly five characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 9), match='Green'>\n",
      "NO MATCH\n",
      "NO MATCH\n",
      "<re.Match object; span=(7, 12), match='Green'>\n",
      "NO MATCH\n"
     ]
    }
   ],
   "source": [
    "run_test_cases(r\"Green(?=.{5})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second and third test cases are followed by four characters, not five, and the last test case isn't followed by anything.\n",
    "\n",
    "Sometimes programming languages won't implement support for all lookarounds (notably, lookbehinds are not in the official JavaScript specification). As an example, to get full support in the RegExr tool, you'll need to set it to use the PCRE regex engine.\n",
    "\n",
    "In this exercise, we're going to use lookarounds to refine the regular expression we build on the last screen to capture mentions of the \"C\" programming language. As a reminder, here is the last of the regular expressions we attempted to use with this exercise earlier, and the resultant titles that match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365                      The new C standards are worth it\n",
       "444           Moz raises $10m Series C from Foundry Group\n",
       "521          Fuchsia: Micro kernel written in C by Google\n",
       "1307            Show HN: Yupp, yet another C preprocessor\n",
       "1326                     The C standard formalized in Coq\n",
       "1365                          GNU C Library 2.23 released\n",
       "1429    Cysignals: signal handling (SIGINT, SIGSEGV, )...\n",
       "1620                        SDCC  Small Device C Compiler\n",
       "1949    Rewriting a Ruby C Extension in Rust: How a Na...\n",
       "2195    MyHTML  HTML Parser on Pure C with POSIX Threa...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_matches(r\"\\b[Cc]\\b[^.+]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use lookarounds to exclude the matches we don't want. We want to:\n",
    "\n",
    "- Keep excluding matches that are followed by . or +, but still match cases where \"C\" falls at the end of the sentence.\n",
    "- Exclude matches that have the word 'Series' immediately preceding them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365                       The new C standards are worth it\n",
       "521           Fuchsia: Micro kernel written in C by Google\n",
       "1307             Show HN: Yupp, yet another C preprocessor\n",
       "1326                      The C standard formalized in Coq\n",
       "1365                           GNU C Library 2.23 released\n",
       "                               ...                        \n",
       "18543                 C-style for loops removed from Swift\n",
       "18549            Show HN: An awesome C library for Windows\n",
       "18649                 Python vs. C/C++ in embedded systems\n",
       "19151                      Ask HN: How to learn C in 2016?\n",
       "19933    Lightweight C library to parse NMEA 0183 sente...\n",
       "Name: title, Length: 102, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"(?<!Series\\s)\\b[Cc]\\b((?![+.])|\\.$)\"\n",
    "\n",
    "c_titles =  titles[titles.str.contains(pattern)]\n",
    "c_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_mentions = titles.str.contains(pattern).sum()\n",
    "c_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BackReferences: Using capture groups in a RegEx pattern\n",
    "\n",
    "Let's say we wanted to identify strings that had words with double letters, like the \"ee\" in \"feed.\" Because we don't know ahead of time what letters might be repeated, we need a way to specify a capture group and then to repeat it. We can do this with backreferences.\n",
    "\n",
    "Whenever we have one or more capture groups, we can refer to them using integers left to right as shown in this regex that matches the string `HelloGoodbye`:\n",
    "\n",
    "![img](img/hello.png)\n",
    "\n",
    "Within a regular expression, we can use a backslash followed by that integer to refer to the group:\n",
    "\n",
    "![img](img/subg.png)\n",
    "\n",
    "The regular expression above will match the text HelloGoodbyeGoodbyeHello. Let's look at how we could write a regex to capture instances of the same two word characters in a row:\n",
    "\n",
    "![img](img/w.png)\n",
    "\n",
    "\n",
    "Let's see this in action using Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(21, 23), match='oo'>\n",
      "<re.Match object; span=(2, 4), match='ee'>\n",
      "None\n",
      "None\n",
      "<re.Match object; span=(13, 15), match='ee'>\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "              \"I'm going to read a book.\",\n",
    "              \"Green is my favorite color.\",\n",
    "              \"My name is Aaron.\",\n",
    "              \"No doubles here.\",\n",
    "              \"I have a pet eel.\"\n",
    "             ]\n",
    "\n",
    "for tc in test_cases:\n",
    "    print(re.search(r\"(\\w)\\1\", tc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there was no match for the word Aaron, despite it containing a double \"a.\" This is because the uppercase and lowercase \"a\" are two different characters, so the backreference does not match.\n",
    "\n",
    "We can easily achieve the same thing using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "test_cases = pd.Series(test_cases)\n",
    "print(test_cases.str.contains(r\"(\\w)\\1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this technique to identify story titles that have repeated words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3102                  Silicon Valley Has a Problem Problem\n",
       "3176                Wire Wire: A West African Cyber Threat\n",
       "3178                         Flexbox Cheatsheet Cheatsheet\n",
       "4797                            The Mindset Mindset (2015)\n",
       "7276     Valentine's Day Special: Bye Bye Tinder, Flirt...\n",
       "10371    Mcdonalds copying cyriak  cows cows cows in th...\n",
       "11575                                    Bang Bang Control\n",
       "11901          Cordless Telephones: Bye Bye Privacy (1991)\n",
       "12697          Solving the the Monty-Hall-Problem in Swift\n",
       "15049    Bye Bye Webrtc2SIP: WebRTC with Asterisk and A...\n",
       "15839          Intellij-Rust Rust Plugin for IntelliJ IDEA\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"\\b(\\w+)\\s\\1\\b\"\n",
    "\n",
    "repeated_words = titles[titles.str.contains(pattern)]\n",
    "repeated_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substituting regular expression matches\n",
    "\n",
    "When we learned to work with basic string methods, we used the str.replace() method to replace simple substrings. We can achieve the same with regular expressions using the re.sub() function. The basic syntax for re.sub() is:\n",
    "\n",
    "`re.sub(pattern, repl, string, flags=0)`\n",
    "\n",
    "The repl parameter is the text that you would like to substitute for the match. Let's look at a simple example where we replace all capital letters in a string with dashes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a-c--f---j\n"
     ]
    }
   ],
   "source": [
    "string = \"aBcDEfGHIj\"\n",
    "\n",
    "print(re.sub(r\"[A-Z]\", \"-\", string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working in pandas, we can use the Series.str.replace() method, which uses nearly identical syntax:\n",
    "\n",
    "`Series.str.replace(pat, repl, flags=0)`\n",
    "\n",
    "Earlier, we discovered that there were multiple different capitalizations for SQL in our dataset. Let's look at how we could make these uniform with the Series.str.replace() method and a regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    SQL\n",
      "1    SQL\n",
      "2    SQL\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "sql_variations = pd.Series([\"SQL\", \"Sql\", \"sql\"])\n",
    "\n",
    "sql_uniform = sql_variations.str.replace(r\"sql\", \"SQL\", flags=re.I)\n",
    "print(sql_uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the same technique to make all the different variations of \"email\" in the dataset uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-d91d8c0cdf52>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  email_uniform = email_variations.str.replace(pattern, 'email', flags = re.I)\n"
     ]
    }
   ],
   "source": [
    "email_variations = pd.Series(['email', 'Email', 'e Mail',\n",
    "                        'e mail', 'E-mail', 'e-mail',\n",
    "                        'eMail', 'E-Mail', 'EMAIL'])\n",
    "\n",
    "\n",
    "pattern = r\"\\be[\\s-]?mail\"\n",
    "\n",
    "email_uniform = email_variations.str.replace(pattern, 'email', flags = re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-1e8f809b7f8d>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  titles_clean = titles.str.replace(pattern, 'email', flags = re.I)\n"
     ]
    }
   ],
   "source": [
    "titles_clean = titles.str.replace(pattern, 'email', flags = re.I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting domains from URLs\n",
    "\n",
    "Over the final three screens in this mission, we'll extract components of URLs from our dataset. As a reminder, most stories on Hacker News contain a link to an external resource.\n",
    "\n",
    "The task we will be performing first is extracting the different components of the URLs in order to analyze them. On this screen, we'll start by extracting just the domains. Below is a list of some of the URLs in the dataset, with the domains highlighted in color, so you can see the part of the string we want to capture.\n",
    "\n",
    "![img](img/domain.pgn)\n",
    "\n",
    "The domain of each URL excludes the protocol (e.g. https://) and the page path (e.g. /Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429).\n",
    "\n",
    "There are several ways that you could use regular expressions to extract the domain, but we suggest the following technique:\n",
    "\n",
    "- Using a series of characters that will match the protocol.\n",
    "- Inside a capture group, using a set that will match the character classes used in the domain.\n",
    "- Because all of the URLs either end with the domain, or continue with page path which starts with / (a character not found in any domains), we don't need to cater for this part of the URL in our regular expression.\n",
    "\n",
    "Once you have extracted the domains, you will be building a frequency table so we can determine the most popular domains. There are over 7,000 unique domains in our dataset, so to make the frequency table easier to analyze, we'll look at only the top 20 domains.\n",
    "\n",
    "We have provided some of the URLs from the dataset which will help you to iterate while you build your regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.amazon.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.interactivedynamicvideo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>www.nytimes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evonomics.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>github.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>phys.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iot.seeed.cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>www.bfilipek.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>beta.crowdfireapp.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>www.valid.ly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>css-cursor.techstream.org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0\n",
       "0                    www.amazon.com\n",
       "1   www.interactivedynamicvideo.com\n",
       "2                   www.nytimes.com\n",
       "3                     evonomics.com\n",
       "4                        github.com\n",
       "5                          phys.org\n",
       "6                      iot.seeed.cc\n",
       "7                  www.bfilipek.com\n",
       "8             beta.crowdfireapp.com\n",
       "9                      www.valid.ly\n",
       "10        css-cursor.techstream.org"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_urls = pd.Series([\n",
    " 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
    " 'http://www.interactivedynamicvideo.com/',\n",
    " 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
    " 'http://evonomics.com/advertising-cannot-maintain-internet-heres-solution/',\n",
    " 'HTTPS://github.com/keppel/pinn',\n",
    " 'Http://phys.org/news/2015-09-scale-solar-youve.html',\n",
    " 'https://iot.seeed.cc',\n",
    " 'http://www.bfilipek.com/2016/04/custom-deleters-for-c-smart-pointers.html',\n",
    " 'http://beta.crowdfireapp.com/?beta=agnipath',\n",
    " 'https://www.valid.ly?param',\n",
    " 'http://css-cursor.techstream.org'\n",
    "])\n",
    "\n",
    "pattern = r\"https?://([\\w\\-\\.]+)\"\n",
    "\n",
    "test_urls_clean = test_urls.str.extract(pattern, flags = re.I)\n",
    "test_urls_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "github.com             1008\n",
       "medium.com              825\n",
       "www.nytimes.com         525\n",
       "www.theguardian.com     248\n",
       "techcrunch.com          245\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains = hn['url'].str.extract(pattern, flags=re.I)\n",
    "\n",
    "domains.value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting URL parts using multiple capture groups\n",
    "\n",
    "Having extracted just the domains from the URLs, on this final screen we'll extract each of the three component parts of the URLs:\n",
    "\n",
    "1. Protocol\n",
    "2. Domain\n",
    "3. Page path\n",
    "\n",
    "![img](img/url.png)\n",
    "\n",
    "In order to do this, we'll create a regular expression with multiple capture groups. Multiple capture groups in regular expressions are defined the same way as single capture groups — using pairs of parentheses.\n",
    "\n",
    "Let's look at how this works using the first few values from the created_at column in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     8/4/2016 11:52\n",
      "1    6/23/2016 22:20\n",
      "2     6/17/2016 0:01\n",
      "3     9/30/2015 4:12\n",
      "4    10/31/2015 9:48\n",
      "Name: created_at, dtype: object\n"
     ]
    }
   ],
   "source": [
    "created_at = hn['created_at'].head()\n",
    "\n",
    "print(created_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use capture groups to extract these dates and times into two columns:\n",
    "\n",
    "![img](img/table.png)\n",
    "\n",
    "In order to do this we can write the following regular expression:\n",
    "\n",
    "![img](img/reg.png)\n",
    "\n",
    "\n",
    "Notice how we put a space character between the capture groups, which matches the space character in the original strings.\n",
    "\n",
    "Let's look at the result of using this regex pattern with Series.str.extract():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/4/2016</td>\n",
       "      <td>11:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/23/2016</td>\n",
       "      <td>22:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/17/2016</td>\n",
       "      <td>0:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/30/2015</td>\n",
       "      <td>4:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/31/2015</td>\n",
       "      <td>9:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1\n",
       "0    8/4/2016  11:52\n",
       "1   6/23/2016  22:20\n",
       "2   6/17/2016   0:01\n",
       "3   9/30/2015   4:12\n",
       "4  10/31/2015   9:48"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"(.+)\\s(.+)\"\n",
    "dates_times = created_at.str.extract(pattern)\n",
    "\n",
    "dates_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a dataframe with each of our capture groups defining a column of data.\n",
    "\n",
    "Now let's write a regular expression that will extract the URL components into individual columns of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https</td>\n",
       "      <td>www.amazon.com</td>\n",
       "      <td>/Technology-Ventures-Enterprise-Thomas-Byers/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http</td>\n",
       "      <td>www.interactivedynamicvideo.com</td>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http</td>\n",
       "      <td>www.nytimes.com</td>\n",
       "      <td>/2007/11/07/movies/07stein.html?_r=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http</td>\n",
       "      <td>evonomics.com</td>\n",
       "      <td>/advertising-cannot-maintain-internet-heres-so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HTTPS</td>\n",
       "      <td>github.com</td>\n",
       "      <td>/keppel/pinn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Http</td>\n",
       "      <td>phys.org</td>\n",
       "      <td>/news/2015-09-scale-solar-youve.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https</td>\n",
       "      <td>iot.seeed.cc</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http</td>\n",
       "      <td>www.bfilipek.com</td>\n",
       "      <td>/2016/04/custom-deleters-for-c-smart-pointers....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http</td>\n",
       "      <td>beta.crowdfireapp.com</td>\n",
       "      <td>/?beta=agnipath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https</td>\n",
       "      <td>www.valid.ly</td>\n",
       "      <td>?param</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>http</td>\n",
       "      <td>css-cursor.techstream.org</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                                1  \\\n",
       "0   https                   www.amazon.com   \n",
       "1    http  www.interactivedynamicvideo.com   \n",
       "2    http                  www.nytimes.com   \n",
       "3    http                    evonomics.com   \n",
       "4   HTTPS                       github.com   \n",
       "5    Http                         phys.org   \n",
       "6   https                     iot.seeed.cc   \n",
       "7    http                 www.bfilipek.com   \n",
       "8    http            beta.crowdfireapp.com   \n",
       "9   https                     www.valid.ly   \n",
       "10   http        css-cursor.techstream.org   \n",
       "\n",
       "                                                    2  \n",
       "0   /Technology-Ventures-Enterprise-Thomas-Byers/d...  \n",
       "1                                                   /  \n",
       "2                /2007/11/07/movies/07stein.html?_r=0  \n",
       "3   /advertising-cannot-maintain-internet-heres-so...  \n",
       "4                                        /keppel/pinn  \n",
       "5                /news/2015-09-scale-solar-youve.html  \n",
       "6                                                      \n",
       "7   /2016/04/custom-deleters-for-c-smart-pointers....  \n",
       "8                                     /?beta=agnipath  \n",
       "9                                              ?param  \n",
       "10                                                     "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"(https?)://([\\w\\.\\-]+)(/?.*)\"\n",
    "\n",
    "test_url_parts = test_urls.str.extract(pattern, flags=re.I)\n",
    "test_url_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http</td>\n",
       "      <td>www.interactivedynamicvideo.com</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http</td>\n",
       "      <td>www.thewire.com</td>\n",
       "      <td>entertainment/2013/04/florida-djs-april-fools-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https</td>\n",
       "      <td>www.amazon.com</td>\n",
       "      <td>Technology-Ventures-Enterprise-Thomas-Byers/dp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http</td>\n",
       "      <td>www.nytimes.com</td>\n",
       "      <td>2007/11/07/movies/07stein.html?_r=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http</td>\n",
       "      <td>arstechnica.com</td>\n",
       "      <td>business/2015/10/comcast-and-other-isps-boost-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20094</th>\n",
       "      <td>https</td>\n",
       "      <td>puri.sm</td>\n",
       "      <td>philosophy/how-purism-avoids-intels-active-man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20095</th>\n",
       "      <td>https</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>@zreitano/the-yc-application-broken-down-and-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20096</th>\n",
       "      <td>http</td>\n",
       "      <td>blog.darknedgy.net</td>\n",
       "      <td>technology/2016/01/01/0/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20097</th>\n",
       "      <td>https</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>@benjiwheeler/how-product-hunt-really-works-d8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20098</th>\n",
       "      <td>https</td>\n",
       "      <td>github.com</td>\n",
       "      <td>jmcarp/robobrowser</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20099 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                                1  \\\n",
       "0       http  www.interactivedynamicvideo.com   \n",
       "1       http                  www.thewire.com   \n",
       "2      https                   www.amazon.com   \n",
       "3       http                  www.nytimes.com   \n",
       "4       http                  arstechnica.com   \n",
       "...      ...                              ...   \n",
       "20094  https                          puri.sm   \n",
       "20095  https                       medium.com   \n",
       "20096   http               blog.darknedgy.net   \n",
       "20097  https                       medium.com   \n",
       "20098  https                       github.com   \n",
       "\n",
       "                                                       2  \n",
       "0                                                         \n",
       "1      entertainment/2013/04/florida-djs-april-fools-...  \n",
       "2      Technology-Ventures-Enterprise-Thomas-Byers/dp...  \n",
       "3                    2007/11/07/movies/07stein.html?_r=0  \n",
       "4      business/2015/10/comcast-and-other-isps-boost-...  \n",
       "...                                                  ...  \n",
       "20094  philosophy/how-purism-avoids-intels-active-man...  \n",
       "20095  @zreitano/the-yc-application-broken-down-and-t...  \n",
       "20096                           technology/2016/01/01/0/  \n",
       "20097  @benjiwheeler/how-product-hunt-really-works-d8...  \n",
       "20098                                 jmcarp/robobrowser  \n",
       "\n",
       "[20099 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_parts = hn['url'].str.extract(pattern, flags=re.I)\n",
    "url_parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using named capture groups to extract data\n",
    "\n",
    "Our final task will be to name these columns, which we'll do using named capture groups. Let's look at the example from the previous screen where we used two capture groups to extract the date and time as two separate columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/4/2016</td>\n",
       "      <td>11:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/23/2016</td>\n",
       "      <td>22:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/17/2016</td>\n",
       "      <td>0:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/30/2015</td>\n",
       "      <td>4:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/31/2015</td>\n",
       "      <td>9:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1\n",
       "0    8/4/2016  11:52\n",
       "1   6/23/2016  22:20\n",
       "2   6/17/2016   0:01\n",
       "3   9/30/2015   4:12\n",
       "4  10/31/2015   9:48"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_at = hn['created_at'].head()\n",
    "\n",
    "pattern = r\"(.+) (.+)\"\n",
    "dates_times = created_at.str.extract(pattern)\n",
    "dates_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to name a capture group we use the syntax `?P<name>`, where name is the name of our capture group. This syntax goes after the open parentheses, but before the regex syntax that defines the capture group:\n",
    "\n",
    "![img](img/named.png)\n",
    "\n",
    "Let's look at the result of this syntax using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/4/2016</td>\n",
       "      <td>11:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/23/2016</td>\n",
       "      <td>22:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/17/2016</td>\n",
       "      <td>0:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/30/2015</td>\n",
       "      <td>4:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/31/2015</td>\n",
       "      <td>9:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   time\n",
       "0    8/4/2016  11:52\n",
       "1   6/23/2016  22:20\n",
       "2   6/17/2016   0:01\n",
       "3   9/30/2015   4:12\n",
       "4  10/31/2015   9:48"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"(?P<date>.+) (?P<time>.+)\"\n",
    "\n",
    "dates_times = created_at.str.extract(pattern)\n",
    "dates_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column has a name corresponding to the name of the capture group it represents.\n",
    "\n",
    "Let's finish this mission by adding names to our capture group from the previous screen to create a dataframe with named columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol</th>\n",
       "      <th>domain</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http</td>\n",
       "      <td>www.interactivedynamicvideo.com</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http</td>\n",
       "      <td>www.thewire.com</td>\n",
       "      <td>entertainment/2013/04/florida-djs-april-fools-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https</td>\n",
       "      <td>www.amazon.com</td>\n",
       "      <td>Technology-Ventures-Enterprise-Thomas-Byers/dp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http</td>\n",
       "      <td>www.nytimes.com</td>\n",
       "      <td>2007/11/07/movies/07stein.html?_r=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http</td>\n",
       "      <td>arstechnica.com</td>\n",
       "      <td>business/2015/10/comcast-and-other-isps-boost-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20094</th>\n",
       "      <td>https</td>\n",
       "      <td>puri.sm</td>\n",
       "      <td>philosophy/how-purism-avoids-intels-active-man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20095</th>\n",
       "      <td>https</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>@zreitano/the-yc-application-broken-down-and-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20096</th>\n",
       "      <td>http</td>\n",
       "      <td>blog.darknedgy.net</td>\n",
       "      <td>technology/2016/01/01/0/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20097</th>\n",
       "      <td>https</td>\n",
       "      <td>medium.com</td>\n",
       "      <td>@benjiwheeler/how-product-hunt-really-works-d8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20098</th>\n",
       "      <td>https</td>\n",
       "      <td>github.com</td>\n",
       "      <td>jmcarp/robobrowser</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20099 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      protocol                           domain  \\\n",
       "0         http  www.interactivedynamicvideo.com   \n",
       "1         http                  www.thewire.com   \n",
       "2        https                   www.amazon.com   \n",
       "3         http                  www.nytimes.com   \n",
       "4         http                  arstechnica.com   \n",
       "...        ...                              ...   \n",
       "20094    https                          puri.sm   \n",
       "20095    https                       medium.com   \n",
       "20096     http               blog.darknedgy.net   \n",
       "20097    https                       medium.com   \n",
       "20098    https                       github.com   \n",
       "\n",
       "                                                    path  \n",
       "0                                                         \n",
       "1      entertainment/2013/04/florida-djs-april-fools-...  \n",
       "2      Technology-Ventures-Enterprise-Thomas-Byers/dp...  \n",
       "3                    2007/11/07/movies/07stein.html?_r=0  \n",
       "4      business/2015/10/comcast-and-other-isps-boost-...  \n",
       "...                                                  ...  \n",
       "20094  philosophy/how-purism-avoids-intels-active-man...  \n",
       "20095  @zreitano/the-yc-application-broken-down-and-t...  \n",
       "20096                           technology/2016/01/01/0/  \n",
       "20097  @benjiwheeler/how-product-hunt-really-works-d8...  \n",
       "20098                                 jmcarp/robobrowser  \n",
       "\n",
       "[20099 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"(?P<protocol>https?)://(?P<domain>[\\w\\.\\-]+)/?(?P<path>.*)\"\n",
    "\n",
    "url_parts = hn['url'].str.extract(pattern, flags = re.I)\n",
    "url_parts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
